{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fE0yAvgimd10MRGq0YqvD73_Nv9_a1Eg",
      "authorship_tag": "ABX9TyNDPH2RPgtUG+8qG88s7VmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushkaraj007/GitHubExpt03_grno/blob/main/Roberta_sentiment_optimzied.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq4S2pMXJAwI",
        "outputId": "f8436ccd-4468-4610-b3f1-ffbefccb7e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO6DrfWnH8Jp",
        "outputId": "033f42a9-a698-4975-8573-271fce53859f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a statement for sentiment analysis: good good doggy\n",
            "Sentiment: positive (Model: cardiffnlp/twitter-roberta-base-sentiment)\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Load the saved RoBERTa model, tokenizer, and model name\n",
        "loaded_model_dict = joblib.load('/content/drive/MyDrive/datasets/roberta_sentiment_model.pkl')\n",
        "loaded_model = loaded_model_dict['model']\n",
        "loaded_tokenizer = loaded_model_dict['tokenizer']\n",
        "model_name = loaded_model_dict['model_name']\n",
        "\n",
        "# Input a statement\n",
        "statement = input(\"Enter a statement for sentiment analysis: \")\n",
        "\n",
        "# Apply sentiment analysis using the loaded model\n",
        "encoded_statement = loaded_tokenizer(statement, return_tensors='pt')\n",
        "output = loaded_model(**encoded_statement)\n",
        "scores = output.logits[0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "scores_dict = {\n",
        "    'negative': scores[0],\n",
        "    'neutral': scores[1],\n",
        "    'positive': scores[2]\n",
        "}\n",
        "\n",
        "# Find the key with the largest value\n",
        "max_key = max(scores_dict, key=scores_dict.get)\n",
        "\n",
        "# Print the sentiment prediction\n",
        "print(f\"Sentiment: {max_key} (Model: {model_name})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the saved RoBERTa model, tokenizer, and model name\n",
        "loaded_model_dict = joblib.load('/content/drive/MyDrive/datasets/roberta_sentiment_model.pkl')\n",
        "loaded_model = loaded_model_dict['model']\n",
        "loaded_tokenizer = loaded_model_dict['tokenizer']\n",
        "model_name = loaded_model_dict['model_name']\n",
        "\n",
        "# Define a function for sentiment analysis\n",
        "def analyze_sentiment(statement):\n",
        "    encoded_statement = loaded_tokenizer(statement, return_tensors='pt')\n",
        "    output = loaded_model(**encoded_statement)\n",
        "    scores = output.logits[0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'negative': scores[0],\n",
        "        'neutral': scores[1],\n",
        "        'positive': scores[2]\n",
        "    }\n",
        "    max_key = max(scores_dict, key=scores_dict.get)\n",
        "    return max_key\n",
        "\n",
        "# Load or initialize the last processed row/index\n",
        "last_processed_row = 0\n",
        "\n",
        "# Specify the local path for the dynamic CSV file\n",
        "local_csv_file_path = '/content/drive/MyDrive/datasets/water_feedback_data - water_feedback_data.csv'\n",
        "# Replace with your local file path\n",
        "\n",
        "# Check if the CSV file exists\n",
        "if not os.path.isfile(local_csv_file_path):\n",
        "    print(\"CSV file does not exist locally. Make sure it's in the specified path.\")\n",
        "else:\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(local_csv_file_path)\n",
        "\n",
        "    # Filter for unprocessed rows (where 'sentiment' column is empty)\n",
        "    unprocessed_df = df[df['sentiment'].isna()]\n",
        "\n",
        "    # Check if there are unprocessed rows\n",
        "    if not unprocessed_df.empty:\n",
        "        # Apply sentiment analysis to unprocessed rows\n",
        "        for index, row in unprocessed_df.iterrows():\n",
        "            statement = row['water_comment']\n",
        "            sentiment = analyze_sentiment(statement)\n",
        "            df.at[index, 'sentiment'] = sentiment\n",
        "\n",
        "        # Update the last processed row/index\n",
        "        last_processed_row = unprocessed_df.index.max() + 1\n",
        "\n",
        "        # Save the updated DataFrame back to the local CSV file\n",
        "        df.to_csv(local_csv_file_path, index=False)\n",
        "\n",
        "        print(\"Sentiments assigned to unprocessed rows and saved to the local CSV file.\")\n",
        "    else:\n",
        "        print(\"No new unprocessed rows to process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuRuGjWUI0g1",
        "outputId": "d62c81ca-bbef-49e9-a94a-c45a0f097f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No new unprocessed rows to process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Load the saved RoBERTa model, tokenizer, and model name\n",
        "loaded_model_dict = joblib.load('/content/drive/MyDrive/datasets/roberta_sentiment_model.pkl')\n",
        "loaded_model = loaded_model_dict['model']\n",
        "loaded_tokenizer = loaded_model_dict['tokenizer']\n",
        "model_name = loaded_model_dict['model_name']\n",
        "\n",
        "# Define a function for sentiment analysis\n",
        "def analyze_sentiment(statement):\n",
        "    encoded_statement = loaded_tokenizer(statement, return_tensors='pt')\n",
        "    output = loaded_model(**encoded_statement)\n",
        "    scores = output.logits[0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'negative': scores[0],\n",
        "        'neutral': scores[1],\n",
        "        'positive': scores[2]\n",
        "    }\n",
        "    max_key = max(scores_dict, key=scores_dict.get)\n",
        "    return max_key\n",
        "\n",
        "# Load or initialize the last processed row/index\n",
        "last_processed_row = 0\n",
        "\n",
        "# Specify the local path for the dynamic CSV file\n",
        "local_csv_file_path = '/content/drive/MyDrive/datasets/water_data_all_combinations - water_data_all_combinations(2).csv'\n",
        "# Replace with your local file path\n",
        "\n",
        "# Check if the CSV file exists\n",
        "if not os.path.isfile(local_csv_file_path):\n",
        "    print(\"CSV file does not exist locally. Make sure it's in the specified path.\")\n",
        "else:\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(local_csv_file_path)\n",
        "\n",
        "    # Check if the 'sentiment' column exists, and if not, create it\n",
        "    if 'sentiment' not in df.columns:\n",
        "        df['sentiment'] = None\n",
        "\n",
        "    # Filter for unprocessed rows (where 'sentiment' column is empty)\n",
        "    unprocessed_df = df[df['sentiment'].isna()]\n",
        "\n",
        "    # Check if there are unprocessed rows\n",
        "    if not unprocessed_df.empty:\n",
        "        # Apply sentiment analysis to unprocessed rows\n",
        "        for index, row in unprocessed_df.iterrows():\n",
        "            statement = row['comments']\n",
        "            sentiment = analyze_sentiment(statement)\n",
        "            df.at[index, 'sentiment'] = sentiment\n",
        "\n",
        "        # Update the last processed row/index\n",
        "        last_processed_row = unprocessed_df.index.max() + 1\n",
        "\n",
        "        # Save the updated DataFrame back to the local CSV file\n",
        "        df.to_csv(local_csv_file_path, index=False)\n",
        "\n",
        "        print(\"Sentiments assigned to unprocessed rows and saved to the local CSV file.\")\n",
        "    else:\n",
        "        print(\"No new unprocessed rows to process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LODmNxwGMR9K",
        "outputId": "07888681-ec47-40d5-c7ba-e8e8701c2e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No new unprocessed rows to process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from datetime import date, timedelta\n",
        "\n",
        "# Load the data from the CSV file\n",
        "data = pd.read_csv('/content/drive/MyDrive/datasets/water_data_all_combinations - water_data_all_combinations (1).csv')  # Replace with your CSV file\n",
        "\n",
        "# Input from the user for ward, beats, and tbs\n",
        "ward = input(\"Enter the ward: \")\n",
        "beats = input(\"Enter the beats: \")\n",
        "tbs = input(\"Enter the tbs: \")\n",
        "\n",
        "# Convert the user input to datetime.date\n",
        "end_date = date.today()\n",
        "start_date = end_date - timedelta(days=30)  # Last 30 days\n",
        "\n",
        "# Filter data based on user input and date range\n",
        "filtered_data = data[\n",
        "    (data['ward'] == ward) &\n",
        "    (data['beats'] == beats) &\n",
        "    (data['tbs'] == tbs) &\n",
        "    (pd.to_datetime(data['date']).dt.date >= start_date) &\n",
        "    (pd.to_datetime(data['date']).dt.date <= end_date)\n",
        "]\n",
        "\n",
        "# Count sentiments\n",
        "sentiment_counts = filtered_data['sentiment'].value_counts().reset_index()\n",
        "sentiment_counts.columns = ['Sentiment', 'Count']\n",
        "\n",
        "# Create a Plotly pie chart\n",
        "fig = px.pie(sentiment_counts, values='Count', names='Sentiment', title=f'Sentiments for Ward: {ward}, Beats: {beats}, TBS: {tbs} (Last Month)')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "IV5nHbf8RSlr",
        "outputId": "603e152c-4739-4dc6-8d85-fbe5e1b62812"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the ward: w1\n",
            "Enter the beats: b2\n",
            "Enter the tbs: t1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"02de88e5-ef14-46dc-bc92-58438291682c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"02de88e5-ef14-46dc-bc92-58438291682c\")) {                    Plotly.newPlot(                        \"02de88e5-ef14-46dc-bc92-58438291682c\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"Sentiment=%{label}\\u003cbr\\u003eCount=%{value}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"labels\":[\"neutral\",\"negative\",\"positive\"],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[176,119,66],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Sentiments for Ward: w1, Beats: b2, TBS: t1 (Last Month)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('02de88e5-ef14-46dc-bc92-58438291682c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}